{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Using previously scraped ticker symbols to scrape daily price data for the stocks of the corresponding conmpanies."
      ],
      "metadata": {
        "id": "hMT5yV1ur5iv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onGgC5jFSV00"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8Bc0dahRpXR"
      },
      "outputs": [],
      "source": [
        "url500 = 'https://raw.githubusercontent.com/arushiag12/stock-price-prediction/main/data/tickers/S%26P500-tickers.csv'\n",
        "tickers500 = pd.read_csv(url500).drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqA9r2lFW6GY"
      },
      "outputs": [],
      "source": [
        "column_names = ['Ticker', 'Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5AuyBEr6Hna"
      },
      "outputs": [],
      "source": [
        "tickers = {\n",
        "    \"500\": tickers500,\n",
        "}\n",
        "years = {\n",
        "    \"2020\" : (dt.datetime(2020, 1, 6), dt.datetime(2021, 1, 4) ),\n",
        "    \"2021\" : (dt.datetime(2021, 1, 4), dt.datetime(2022, 1, 3) ),\n",
        "    \"2022\" : (dt.datetime(2022, 1, 3), dt.datetime(2023, 1, 2) ),\n",
        "    \"2023\" : (dt.datetime(2023, 1, 2), dt.datetime(2024, 1, 1) ),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUp-WHIPzssq"
      },
      "outputs": [],
      "source": [
        "def scrape_data(tickers, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Scrapes data given a list of ticker symbols, a start date, and an end date.\n",
        "    Returns a DataFrame containing the scraped data.\n",
        "    \"\"\"\n",
        "\n",
        "    features = pd.DataFrame(columns=column_names)\n",
        "\n",
        "    for curr_ticker in tickers['Symbol']:\n",
        "        curr_date = start_date\n",
        "\n",
        "        while curr_date < end_date:\n",
        "            try:\n",
        "                data = yf.download(curr_ticker, start=curr_date.strftime(\"%Y-%m-%d\"), end=(curr_date+dt.timedelta(days=1)).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "                if not data.empty:\n",
        "                    data.reset_index()\n",
        "                    data['Ticker'] = curr_ticker\n",
        "                    data['Date'] = curr_date.strftime(\"%Y-%m-%d\")\n",
        "                    features = pd.concat([features, data], ignore_index=True)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            curr_date += dt.timedelta(days=1)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LlOrdPhRy7sI"
      },
      "outputs": [],
      "source": [
        "cap = \"500\"\n",
        "year = \"2020\"\n",
        "\n",
        "ticker = tickers[cap]\n",
        "year_start, year_end = years[year]\n",
        "\n",
        "data = scrape_data(ticker, year_start, year_end)\n",
        "data.to_csv(f\"S&P{cap}_data_{year}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xJRTfr1sV1wR"
      },
      "outputs": [],
      "source": [
        "cap = \"500\"\n",
        "year = \"2021\"\n",
        "\n",
        "ticker = tickers[cap]\n",
        "year_start, year_end = years[year]\n",
        "\n",
        "data = scrape_data(ticker, year_start, year_end)\n",
        "data.to_csv(f\"S&P{cap}_data_{year}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDXjIcSRdCWz"
      },
      "outputs": [],
      "source": [
        "cap = \"500\"\n",
        "year = \"2022\"\n",
        "\n",
        "ticker = tickers[cap]\n",
        "year_start, year_end = years[year]\n",
        "\n",
        "data = scrape_data(ticker, year_start, year_end)\n",
        "data.to_csv(f\"S&P{cap}_data_{year}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BTkc7Sw2dGc4"
      },
      "outputs": [],
      "source": [
        "cap = \"500\"\n",
        "year = \"2023\"\n",
        "\n",
        "ticker = tickers[cap]\n",
        "year_start, year_end = years[year]\n",
        "\n",
        "data = scrape_data(ticker, year_start, year_end)\n",
        "data.to_csv(f\"S&P{cap}_data_{year}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}